# Quick Start Guide - Mimic Robot Training (Multi-Group + Auto-Upload)

## ğŸ¯ Training in 60 Seconds
hf upload Mimic-Robotics/act_odin_red_x_handover_20k outputs/train/act_odin_red_x_handover_and_place_center/checkpoints/020000
### Step 1: Choose Your Setup
```bash
# List available dataset groups
./mimic_deployment/training_scripts/train_manager.sh --list-groups

# List available policies
./mimic_deployment/training_scripts/train_manager.sh --list-policies
```

### Step 2: Train Your Model
```bash
# Train xVLA on all datasets (recommended for first run)
./mimic_deployment/training_scripts/train_manager.sh --policy xvla --dataset-group all_datasets

# Train Pi0.5 on high quality datasets (recommended for Pi models)
./mimic_deployment/training_scripts/train_manager.sh --policy pi05 --dataset-group high_quality

# Train ACT on stationary datasets
./mimic_deployment/training_scripts/train_manager.sh --policy act --dataset-group stationary

# ğŸ†• NEW: Train on multiple dataset groups sequentially
./mimic_deployment/training_scripts/train_manager.sh --policy xvla --dataset-group high_quality,most_recent --wait-for-completion

# ğŸ†• NEW: Train multiple policies on multiple groups with auto-upload
./mimic_deployment/training_scripts/train_manager.sh --policy xvla,pi05 --dataset-group high_quality,most_recent --push-to-hub --wait-for-completion
```

### Step 3: Monitor Progress
```bash
# Find your log file
ls -lth outputs/logs/

# Watch training in real-time
tail -f outputs/logs/xvla_odin_all_datasets.log
```

---

## ğŸ“Š Quick Reference

### Recommended Combinations

| Priority | Policy | Dataset Group | Computer | Why? |
|----------|--------|---------------|----------|------|
| 1ï¸âƒ£ | `xvla` | `all_datasets` | Odin | Best generalization, most data |
| 2ï¸âƒ£ | `pi05` | `high_quality` | Odin | Latest model, best quality data |
| 3ï¸âƒ£ | `groot` | `most_recent` | Odin | Humanoid foundation, recent data |
| 4ï¸âƒ£ | `pi0` | `all_datasets` | Odin | Solid baseline |
| 5ï¸âƒ£ | `act` | `stationary` | Mathias | Fast, lightweight |
| 6ï¸âƒ£ | `wall_oss` | `high_quality` | Odin | ğŸ†• Embodied foundation model |

### Computer Assignments

- **Odin (RTX 3090 Ti, 22GB):** Train Pi models (pi05, pi0), xVLA, Wall-OSS
- **Jupiter (RTX 5070, 12GB):** Train xVLA, ACT, Wall-OSS
- **Mathias (RTX 3080 Ti, 10GB):** Train ACT, Wall-OSS

---

## ğŸ”¥ Common Training Commands

### Train on Different Dataset Groups
```bash
# All available datasets (27 datasets)
./mimic_deployment/training_scripts/train_manager.sh --policy xvla --dataset-group all_datasets

# High quality datasets (16 datasets)
./mimic_deployment/training_scripts/train_manager.sh --policy pi05 --dataset-group high_quality

# Most recent datasets (10 datasets)
./mimic_deployment/training_scripts/train_manager.sh --policy groot --dataset-group most_recent

# Stationary bimanual only (20 datasets)
./mimic_deployment/training_scripts/train_manager.sh --policy act --dataset-group stationary

# Mobile displacement tasks (7 datasets)
./mimic_deployment/training_scripts/train_manager.sh --policy xvla --dataset-group displacement_only

# ğŸ†• NEW: Train on multiple groups sequentially
./mimic_deployment/training_scripts/train_manager.sh --policy xvla --dataset-group high_quality,most_recent,new_hands
```

### ğŸ†• Multi-Group Sequential Training
```bash
# Train xVLA on high_quality, then most_recent, then all_datasets
./mimic_deployment/training_scripts/train_manager.sh --policy xvla --dataset-group high_quality,most_recent,all_datasets --wait-for-completion

# Train multiple policies on multiple groups (comprehensive experiment)
./mimic_deployment/training_scripts/train_manager.sh --policy xvla,pi05,groot --dataset-group high_quality,most_recent --push-to-hub --wait-for-completion
```

### Custom Batch Sizes
```bash
# Reduce batch size if OOM
./mimic_deployment/training_scripts/train_manager.sh --policy pi05 --dataset-group all_datasets --batch-size 1

# Increase batch size for faster training
./mimic_deployment/training_scripts/train_manager.sh --policy act --dataset-group stationary --batch-size 12
```

### Custom Training Steps
```bash
# Quick test run (1000 steps)
./mimic_deployment/training_scripts/train_manager.sh --policy xvla --dataset-group high_quality --steps 1000

# Extended training (50000 steps)
./mimic_deployment/training_scripts/train_manager.sh --policy act --dataset-group all_datasets --steps 50000
```

---

## ğŸš¦ Training Status

### Check What's Running
```bash
# See active training jobs
ps aux | grep lerobot-train

# See GPU usage
watch -n 1 nvidia-smi

# Check all log files
ls -lth outputs/logs/
```

### Stop Training
```bash
# Find PID from log output, then:
kill <PID>

# Or stop all training
pkill -f lerobot-train
```

---

## ğŸ“ Output Locations

```
outputs/
â”œâ”€â”€ logs/                                    # Training logs
â”‚   â”œâ”€â”€ xvla_odin_all_datasets.log
â”‚   â”œâ”€â”€ pi05_odin_high_quality.log
â”‚   â””â”€â”€ ...
â””â”€â”€ train/                                   # Training outputs
    â”œâ”€â”€ xvla_odin_all_datasets/
    â”‚   â”œâ”€â”€ checkpoints/                     # Model checkpoints
    â”‚   â”‚   â”œâ”€â”€ 005000/
    â”‚   â”‚   â”œâ”€â”€ 010000/
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â””â”€â”€ train_config.json
    â””â”€â”€ ...
```

---

## ğŸ†˜ Quick Troubleshooting

### Problem: Out of Memory (OOM)
**Solution:** Reduce batch size
```bash
./mimic_deployment/train_manager.sh --policy pi05 --dataset-group all_datasets --batch-size 1
```

### Problem: Training too slow
**Solution:** Reduce number of workers or use smaller dataset group
```bash
./mimic_deployment/train_manager.sh --policy xvla --dataset-group high_quality --num-workers 4
```

### Problem: Can't find dataset group
**Solution:** List available groups
```bash
./mimic_deployment/train_manager.sh --list-groups
```

### Problem: Wrong computer detected
**Solution:** Override computer name
```bash
./mimic_deployment/train_manager.sh --policy xvla --dataset-group all_datasets --computer jupiter
```

---

## ğŸ“ Training Strategy

### For Maximum Performance
1. Start with `xvla` on `high_quality` (best generalization)
2. Train `pi05` on `all_datasets` (latest tech)
3. Train `groot` on `most_recent` (foundation model)

### For Quick Results
1. Train `act` on `stationary` (fast, lightweight)
2. Use smaller dataset groups (`high_quality`, `most_recent`)
3. Reduce training steps to 10000

### For Experimentation
1. Use `--dry-run` to test configurations
2. Start with smaller groups (`new_hands`, `most_recent`)
3. Use lower batch sizes to fit more experiments on one GPU

---

## ğŸ“š Full Documentation

For comprehensive documentation, see:
- [TRAINING_INFRASTRUCTURE.md](TRAINING_INFRASTRUCTURE.md) - Complete guide
- [dataset_groups.yaml](dataset_groups.yaml) - Dataset definitions
- Individual training scripts in `training_scripts/*/`

---

**Ready to train? Pick a command above and get started! ğŸš€**




#custom ACT

./mimic_deployment/training_scripts/train_manager.sh \
  --policy act,pi05,groot,pi0,wall_oss \
  --dataset-group red_x_handover_and_place_tictactoe_v8 \
  --batch-size 10 \
  --action-steps 30 \
  --chunk-size 100 


./mimic_deployment/training_scripts/train_manager.sh \
  --policy act,pi05,groot,pi0,wall_oss \
  --dataset-group red_x_handover_and_place_tictactoe_v8 \
  --batch-size 10 \
  --action-steps 30 \
  --chunk-size 100 



./mimic_deployment/training_scripts/train_manager.sh \
  --policy pi05,groot,pi0,wall_oss \
  --dataset-group red_x_handover_and_place_tictactoe_v8



  ./mimic_deployment/training_scripts/train_manager.sh \
  --policy act,pi05,groot,pi0,wall_oss \
  --dataset-group red_x_handover_and_place_tictactoe_slower \
  --batch-size 10 


  -> action step should be the number of action which it moves from and the 
  chunk size is teh number generate to predict future


  hf upload Mimic-Robotics/act_odin_red_x_handover_10action_20k outputs/train/act_odin_red_x_handover_and_place_tictactoe_v4/checkpoints/020000/pretrained_model



hf upload Mimic-Robotics/act_odin_red_x_30a_20k  outputs/train/act_odin_red_x_handover_and_place_tictactoe_v8/checkpoints/020000/pretrained_model
hf upload Mimic-Robotics/act_odin_red_x_30a_40k  outputs/train/act_odin_red_x_handover_and_place_tictactoe_v8/checkpoints/040000/pretrained_model
hf upload Mimic-Robotics/act_odin_red_x_30a_60k  outputs/train/act_odin_red_x_handover_and_place_tictactoe_v8/checkpoints/060000/pretrained_model
hf upload Mimic-Robotics/act_odin_red_x_30a_80k  outputs/train/act_odin_red_x_handover_and_place_tictactoe_v8/checkpoints/080000/pretrained_model


